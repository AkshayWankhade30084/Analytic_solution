{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "def data_transform(raw_df):\n",
        "    \"\"\"Transform raw data into clean format\"\"\"\n",
        "    # Data Transformation\n",
        "    default_values = {\n",
        "        'Age': 0,\n",
        "        'Tenure': 0,\n",
        "        'MonthlyCharges': np.nanmedian(raw_df['MonthlyCharges']),\n",
        "        'TotalCharges': np.nanmedian(raw_df['TotalCharges']),\n",
        "        'Gender': 'Unknown',\n",
        "        'ContractType': 'Unknown',\n",
        "        'InternetService': 'Unknown',\n",
        "        'TechSupport': 'Unknown',\n",
        "        'Churn': 'No'\n",
        "    }\n",
        "\n",
        "    # Missing value handling\n",
        "    for col in ['Age', 'Tenure', 'MonthlyCharges', 'TotalCharges', 'Gender',\n",
        "                'ContractType', 'InternetService', 'TechSupport', 'Churn']:\n",
        "        if col in raw_df.columns:\n",
        "            raw_df[col] = raw_df[col].fillna(default_values[col])\n",
        "\n",
        "    # Standardizing the values\n",
        "    raw_df['Gender'] = raw_df['Gender'].str.upper()\n",
        "    raw_df['Churn'] = raw_df['Churn'].replace({'Yes': 1, 'No': 0, True: 1, False: 0})\n",
        "\n",
        "    # New feature calculation\n",
        "    raw_df['LifetimeValue'] = raw_df['MonthlyCharges'] * raw_df['Tenure']\n",
        "\n",
        "    # Add current timestamp to DataFrame\n",
        "    utc_now = datetime.now(pytz.utc)\n",
        "    ist_time = utc_now.astimezone(pytz.timezone('Asia/Kolkata'))\n",
        "    raw_df['load_timestamp_ist'] = ist_time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    return raw_df\n",
        "\n",
        "\n",
        "def create_dimension_tables():\n",
        "    \"\"\"Create all dimension tables\"\"\"\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Customer dimension\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS dim_customer (\n",
        "        customer_key INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        customer_id INTEGER UNIQUE ,\n",
        "        age INTEGER,\n",
        "        age_group TEXT,\n",
        "        gender TEXT,\n",
        "        valid_from DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
        "        valid_to DATETIME DEFAULT '9999-12-31',\n",
        "        is_current BOOLEAN DEFAULT 1\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    # Contract dimension\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS dim_contract (\n",
        "        contract_key INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        contract_type TEXT UNIQUE,\n",
        "        duration_months INTEGER,\n",
        "        is_month_to_month BOOLEAN\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    # Service dimension\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS dim_service (\n",
        "        service_key INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        internet_service TEXT UNIQUE,\n",
        "        service_category TEXT,\n",
        "        has_service BOOLEAN\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    # Tech Support dimension\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS dim_tech_support (\n",
        "        support_key INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        tech_support TEXT UNIQUE,\n",
        "        has_support BOOLEAN\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    # Time dimension (based on tenure)\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS dim_tenure (\n",
        "        tenure_key INTEGER PRIMARY KEY,\n",
        "        tenure_months INTEGER UNIQUE,\n",
        "        tenure_years INTEGER,\n",
        "        tenure_category TEXT\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    conn.commit()\n",
        "\n",
        "\n",
        "def create_fact_table():\n",
        "    \"\"\"Create the fact table\"\"\"\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS fact_churn (\n",
        "        fact_key INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        customer_key INTEGER,\n",
        "        contract_key INTEGER,\n",
        "        service_key INTEGER,\n",
        "        support_key INTEGER,\n",
        "        tenure_key INTEGER,\n",
        "        monthly_charges REAL,\n",
        "        total_charges REAL,\n",
        "        lifetime_value REAL,\n",
        "        churn_status BOOLEAN,\n",
        "        load_timestamp DATETIME,\n",
        "        FOREIGN KEY (customer_key) REFERENCES dim_customer(customer_key),\n",
        "        FOREIGN KEY (contract_key) REFERENCES dim_contract(contract_key),\n",
        "        FOREIGN KEY (service_key) REFERENCES dim_service(service_key),\n",
        "        FOREIGN KEY (support_key) REFERENCES dim_tech_support(support_key),\n",
        "        FOREIGN KEY (tenure_key) REFERENCES dim_tenure(tenure_key)\n",
        "    )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "\n",
        "\n",
        "def load_dimension_data(transformed_df):\n",
        "    \"\"\"Load data into dimension tables\"\"\"\n",
        "\n",
        "    # Load dim_customer\n",
        "#transformed_df=data_clean\n",
        "    customer_data = transformed_df[['customer_id', 'age', 'gender']].drop_duplicates()\n",
        "    customer_data['age_group'] = pd.cut(customer_data['age'],\n",
        "                                      bins=[0, 18, 30, 45, 60, 100],\n",
        "                                      labels=['<18', '18-30', '31-45', '46-60', '60+'])\n",
        "  #   cursor.execute(\"\"\"\n",
        "  #  delete from  dim_customer\n",
        "  #   \"\"\")\n",
        "    cursor.executemany(\"\"\"\n",
        "    INSERT INTO dim_customer (customer_id, age, gender, age_group)\n",
        "    VALUES (?, ?, ?, ?)\n",
        "    ON CONFLICT(customer_id) DO UPDATE SET\n",
        "        age = excluded.age,\n",
        "        gender = excluded.gender,\n",
        "        age_group = excluded.age_group\n",
        "\"\"\", customer_data[['customer_id', 'age', 'gender', 'age_group']].values.tolist())\n",
        "\n",
        "    # Load dim_contract\n",
        "    # Load dim_contract\n",
        "    contract_data = pd.DataFrame({\n",
        "        'contract_type': ['Month-to-Month','One-Year','Two-Year'],\n",
        "        'duration_months': [1, 12, 24],\n",
        "        'is_month_to_month': [True, False, False]\n",
        "    })\n",
        "  #   cursor.execute(\"\"\"\n",
        "  #  delete from  dim_contract\n",
        "  #   \"\"\")\n",
        "    cursor.executemany(\"\"\"\n",
        "    INSERT INTO dim_contract (contract_type, duration_months, is_month_to_month)\n",
        "    VALUES (?, ?, ?)\n",
        "    ON CONFLICT(contract_type) DO UPDATE SET\n",
        "        duration_months = excluded.duration_months,\n",
        "        is_month_to_month = excluded.is_month_to_month\n",
        "\"\"\", contract_data[['contract_type', 'duration_months', 'is_month_to_month']].values.tolist())\n",
        "\n",
        "\n",
        "     # Load dim_service\n",
        "    service_data = pd.DataFrame({\n",
        "         'internet_service': ['Fiber Optic', 'DSL', 'Unknown'],\n",
        "         'service_category': ['Premium', 'Standard', 'None'],\n",
        "         'has_service': [True, True, False]\n",
        "     })\n",
        "\n",
        "    # Then use UPSERT for insertion/updates\n",
        "    cursor.executemany(\"\"\"\n",
        "    INSERT INTO dim_service (internet_service, service_category, has_service)\n",
        "    VALUES (?, ?, ?)\n",
        "    ON CONFLICT(internet_service) DO UPDATE SET\n",
        "        service_category = excluded.service_category,\n",
        "        has_service = excluded.has_service\n",
        "\"\"\", service_data[['internet_service', 'service_category', 'has_service']].values.tolist())\n",
        "\n",
        "     #Load dim_tech_support\n",
        "    support_data = pd.DataFrame({\n",
        "         'tech_support': ['Yes', 'No', 'Unknown'],\n",
        "         'has_support': [True, False, False]\n",
        "     })\n",
        "\n",
        "    # Then use UPSERT for smart inserts/updates\n",
        "    cursor.executemany(\"\"\"\n",
        "    INSERT INTO dim_tech_support (tech_support, has_support)\n",
        "    VALUES (?, ?)\n",
        "    ON CONFLICT(tech_support) DO UPDATE SET\n",
        "        has_support = excluded.has_support\n",
        "\"\"\", support_data[['tech_support', 'has_support']].values.tolist())\n",
        "\n",
        "    # Load dim_tenure\n",
        "    max_tenure = transformed_df['tenure_months'].max()\n",
        "    tenure_data = pd.DataFrame({'tenure_months': range(0, int(max_tenure)+1)})\n",
        "    tenure_data['tenure_key'] = tenure_data['tenure_months'] + 1\n",
        "    tenure_data['tenure_years'] = tenure_data['tenure_months'] // 12\n",
        "    tenure_data['tenure_category'] = pd.cut(tenure_data['tenure_months'],\n",
        "                                           bins=[-1, 0, 6, 12, 24, 60, float('inf')],\n",
        "                                           labels=['New', '0-6m', '6-12m', '1-2y', '2-5y', '5y+'])\n",
        "\n",
        "    cursor.executemany(\"\"\"\n",
        "    INSERT INTO dim_tenure (tenure_key, tenure_months, tenure_years, tenure_category)\n",
        "    VALUES (?, ?, ?, ?)\n",
        "    ON CONFLICT(tenure_months) DO UPDATE SET\n",
        "        tenure_years = excluded.tenure_years,\n",
        "        tenure_category = excluded.tenure_category\n",
        "\"\"\", tenure_data[['tenure_key', 'tenure_months', 'tenure_years', 'tenure_category']].values.tolist())\n",
        "\n",
        "    # def drop_table_diemension():\n",
        "\n",
        "    #   ## note: this method to just avoid duplicate. In real time needto implement change data capture here as done for fact table\n",
        "    #   cursor.execute(\"\"\"DROP TABLE IF EXISTS dim_customer\"\"\")\n",
        "    #   cursor.execute(\"\"\"DROP TABLE IF EXISTS dim_contract\"\"\")\n",
        "    #   cursor.execute(\"\"\"DROP TABLE IF EXISTS dim_service\"\"\")\n",
        "    #   cursor.execute(\"\"\"DROP TABLE IF EXISTS dim_tech_support\"\"\")\n",
        "    #   cursor.execute(\"\"\"DROP TABLE IF EXISTS dim_tenure\"\"\")\n",
        "\n"
      ],
      "metadata": {
        "id": "8cDQnnyrw8AL"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def incremental_load_fact_data(transformed_df):\n",
        "    \"\"\"Load data into fact table incrementally using MERGE-like approach\"\"\"\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    try:\n",
        "        # Create temporary staging table with all required columns\n",
        "        cursor.execute(\"\"\"\n",
        "        CREATE  TABLE IF NOT EXISTS  temp_fact_churn (\n",
        "            customer_id INTEGER,\n",
        "            contract_type TEXT,\n",
        "            internet_service TEXT,\n",
        "            tech_support TEXT,\n",
        "            tenure_months INTEGER,\n",
        "            monthly_charges REAL,\n",
        "            total_charges REAL,\n",
        "            lifetime_value REAL,\n",
        "            churn_status BOOLEAN,\n",
        "            load_timestamp DATETIME\n",
        "        )\n",
        "        \"\"\")\n",
        "\n",
        "        # # Prepare and load data into temp table\n",
        "        # staging_data = transformed_df.rename(columns={\n",
        "        #     'CustomerID': 'customer_id',\n",
        "        #     'ContractType': 'contract_type',\n",
        "        #     'InternetService': 'internet_service',\n",
        "        #     'TechSupport': 'tech_support',\n",
        "        #     'Tenure': 'tenure_months',\n",
        "        #     'MonthlyCharges': 'monthly_charges',\n",
        "        #     'TotalCharges': 'total_charges',\n",
        "        #     'LifetimeValue': 'lifetime_value',\n",
        "        #     'Churn': 'churn_status',\n",
        "        #     'load_timestamp_ist': 'load_timestamp'\n",
        "        # })\n",
        "\n",
        "        # Select columns in correct order matching temp table definition\n",
        "        staging_data = transformed_df[[\n",
        "            'customer_id', 'contract_type', 'internet_service', 'tech_support',\n",
        "            'tenure_months', 'monthly_charges', 'total_charges', 'lifetime_value',\n",
        "            'churn_status', 'load_timestamp'\n",
        "        ]]\n",
        "\n",
        "        # Load to temp table\n",
        "        staging_data.to_sql('temp_fact_churn', conn, if_exists='replace', index=False)\n",
        "\n",
        "        # Begin transaction\n",
        "        cursor.execute(\"BEGIN TRANSACTION\")\n",
        "\n",
        "\n",
        "        cursor.execute(\"\"\"\n",
        "    UPDATE fact_churn\n",
        "    SET\n",
        "        monthly_charges = tf.monthly_charges,\n",
        "        total_charges = tf.total_charges,\n",
        "        lifetime_value = tf.lifetime_value,\n",
        "        churn_status = tf.churn_status,\n",
        "        load_timestamp = tf.load_timestamp\n",
        "    FROM fact_churn fc\n",
        "    LEFT JOIN dim_customer c ON fc.customer_key = c.customer_key\n",
        "    LEFT JOIN dim_contract ct ON fc.contract_key = ct.contract_key\n",
        "    LEFT JOIN dim_service s ON fc.service_key = s.service_key\n",
        "    LEFT JOIN dim_tech_support ts ON fc.support_key = ts.support_key\n",
        "    LEFT JOIN dim_tenure t ON fc.tenure_key = t.tenure_key\n",
        "    INNER JOIN temp_fact_churn tf ON tf.customer_id = c.customer_id\n",
        "                AND tf.contract_type = ct.contract_type\n",
        "                AND tf.internet_service = s.internet_service\n",
        "                AND tf.tech_support = ts.tech_support\n",
        "                AND tf.tenure_months = t.tenure_months\n",
        "    WHERE fc.monthly_charges <> tf.monthly_charges OR\n",
        "          fc.total_charges <> tf.total_charges OR\n",
        "          fc.lifetime_value <> tf.lifetime_value OR\n",
        "          fc.churn_status <> tf.churn_status\n",
        "\"\"\")\n",
        "        updated_count = cursor.rowcount\n",
        "\n",
        "        # # STEP 2: INSERT new records\n",
        "        cursor.execute(\"\"\"\n",
        "        INSERT INTO fact_churn (\n",
        "            customer_key, contract_key, service_key, support_key,\n",
        "            tenure_key, monthly_charges, total_charges, lifetime_value,\n",
        "            churn_status, load_timestamp\n",
        "        )\n",
        "        SELECT\n",
        "            c.customer_key,\n",
        "            ct.contract_key,\n",
        "            s.service_key,\n",
        "            ts.support_key,\n",
        "            t.tenure_key,\n",
        "            tf.monthly_charges,\n",
        "            tf.total_charges,\n",
        "            tf.lifetime_value,\n",
        "            tf.churn_status,\n",
        "            tf.load_timestamp\n",
        "        FROM temp_fact_churn tf\n",
        "        JOIN dim_customer c ON tf.customer_id = c.customer_id\n",
        "        JOIN dim_contract ct ON tf.contract_type = ct.contract_type\n",
        "        JOIN dim_service s ON tf.internet_service = s.internet_service\n",
        "        JOIN dim_tech_support ts ON tf.tech_support = ts.tech_support\n",
        "        JOIN dim_tenure t ON tf.tenure_months = t.tenure_months\n",
        "        LEFT JOIN fact_churn fc ON\n",
        "            fc.customer_key = c.customer_key AND\n",
        "            fc.contract_key = ct.contract_key AND\n",
        "            fc.service_key = s.service_key AND\n",
        "            fc.support_key = ts.support_key AND\n",
        "            fc.tenure_key = t.tenure_key\n",
        "        WHERE fc.fact_key IS NULL  -- Only insert if record doesn't exist\n",
        "        \"\"\")\n",
        "        inserted_count = cursor.rowcount\n",
        "\n",
        "        # Commit transaction\n",
        "        conn.commit()\n",
        "       #print(f\"Incremental load completed: {updated_count} records updated\")\n",
        "        print(f\"Incremental load completed: {updated_count} records updated, {inserted_count} records inserted\")\n",
        "        return updated_count, inserted_count\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        conn.rollback()\n",
        "        print(f\"Error during incremental load: {str(e)}\")\n",
        "    #     raise\n",
        "    # finally:\n",
        "    #      # Clean up\n",
        "    #      cursor.execute(\"DROP TABLE IF EXISTS temp_fact_churn\")"
      ],
      "metadata": {
        "id": "bJl2SFbgBTPU"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "import numpy as np\n",
        "\n",
        "   # 1. Load data from GitHub\n",
        "   #https://github.com/AkshayWankhade30084/Analytic_solution/blob/main/customer_churn_data_update_insert_check.csv\n",
        "github_url = 'https://raw.githubusercontent.com/AkshayWankhade30084/Analytic_solution/refs/heads/main/customer_churn_data.csv'\n",
        "df = pd.read_csv(github_url)\n",
        "\n",
        "# 2. Create SQLite database connection\n",
        "conn = sqlite3.connect('customer_churn.db')  # Creates persistent database file\n",
        "\n",
        "# 3. Create staging table\n",
        "try:\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # SQLite doesn't support schemas, so we'll use a prefix for staging tables\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS stg_customer_churn_data (\n",
        "        CustomerID INTEGER,\n",
        "        Age INTEGER,\n",
        "        Gender TEXT,\n",
        "        Tenure INTEGER,\n",
        "        MonthlyCharges REAL,\n",
        "        ContractType TEXT,\n",
        "        InternetService TEXT,\n",
        "        TotalCharges REAL,\n",
        "        TechSupport TEXT,\n",
        "        Churn TEXT,\n",
        "        load_timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    # Load data into staging table\n",
        "    df.to_sql('stg_customer_churn_data', conn, if_exists='replace', index=False)\n",
        "\n",
        "    # Verify data loaded correctly\n",
        "    print(\"Data successfully loaded into stg_customers (staging table)\")\n",
        "    staging_data = pd.read_sql(\"SELECT * FROM stg_customer_churn_data LIMIT 5\", conn)\n",
        "    #print(\"\\nSample data from staging table:\")\n",
        "    #display(staging_data)\n",
        "\n",
        "    # Read raw data\n",
        "    raw_df = pd.read_sql(\"SELECT * FROM stg_customer_churn_data\", conn)\n",
        "    data_clean=data_transform(raw_df)\n",
        "    # Create dimension tables if they don't exist\n",
        "    create_dimension_tables()\n",
        "\n",
        "\n",
        "\n",
        "    # # Load dimension data (only if empty)\n",
        "    # dim_counts = pd.read_sql(\"\"\"\n",
        "    #     SELECT 'dim_customer' as table, COUNT(*) as count FROM dim_customer\n",
        "    #     UNION ALL SELECT 'dim_contract', COUNT(*) FROM dim_contract\n",
        "    #     UNION ALL SELECT 'dim_service', COUNT(*) FROM dim_service\n",
        "    #     UNION ALL SELECT 'dim_tech_support', COUNT(*) FROM dim_tech_support\n",
        "    #     UNION ALL SELECT 'dim_tenure', COUNT(*) FROM dim_tenure\n",
        "    # \"\"\", conn)\n",
        "\n",
        "\n",
        "    # replace\n",
        "\n",
        "\n",
        "    data_clean = data_clean.rename(columns={\n",
        "            'CustomerID': 'customer_id',\n",
        "            'Age':'age',\n",
        "            'Gender':'gender',\n",
        "            'ContractType': 'contract_type',\n",
        "            'InternetService': 'internet_service',\n",
        "            'TechSupport': 'tech_support',\n",
        "            'Tenure': 'tenure_months',\n",
        "            'MonthlyCharges': 'monthly_charges',\n",
        "             'TotalCharges': 'total_charges',\n",
        "             'LifetimeValue': 'lifetime_value',\n",
        "             'Churn': 'churn_status',\n",
        "             'load_timestamp_ist': 'load_timestamp'\n",
        "        })\n",
        "\n",
        "    # if dim_counts['count'].sum() == 0:\n",
        "    load_dimension_data(data_clean)\n",
        "    print(\"Data successfully loaded into diemension tables\")\n",
        "  #  drop_table_diemension()\n",
        "    # Create fact table if it doesn't exist\n",
        "    create_fact_table()\n",
        "\n",
        "  #  incremental_load_fact_data(data_clean)\n",
        "    # Incremental load of fact data\n",
        "    incremental_load_fact_data(data_clean)\n",
        "    print(\"Data successfully loaded into fact tables\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading data: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S83hH6AZ8Fhe",
        "outputId": "58ff1f95-741f-403f-8d5c-f9e26c42b321"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully loaded into stg_customers (staging table)\n",
            "Data successfully loaded into diemension tables\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-164-3248371620.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  raw_df['Churn'] = raw_df['Churn'].replace({'Yes': 1, 'No': 0, True: 1, False: 0})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Incremental load completed: 0 records updated, 0 records inserted\n",
            "Data successfully loaded into fact tables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "057f0f84",
        "outputId": "5eaa1539-6cde-4079-fe45-c2f2f13455ff"
      },
      "source": [
        "# # Export staging table data to CSV\n",
        "# staging_df = pd.read_sql(\"SELECT * FROM stg_customer_churn_data\", conn)\n",
        "# staging_df.to_csv('stg_customer_churn_data.csv', index=False)\n",
        "# print(\"Exported stg_customer_churn_data.csv\")\n",
        "\n",
        "# # Export dimension tables data to CSV\n",
        "# dim_customer_df = pd.read_sql(\"SELECT * FROM dim_customer\", conn)\n",
        "# dim_customer_df.to_csv('dim_customer.csv', index=False)\n",
        "# print(\"Exported dim_customer.csv\")\n",
        "\n",
        "# dim_contract_df = pd.read_sql(\"SELECT * FROM dim_contract\", conn)\n",
        "# dim_contract_df.to_csv('dim_contract.csv', index=False)\n",
        "# print(\"Exported dim_contract.csv\")\n",
        "\n",
        "# dim_service_df = pd.read_sql(\"SELECT * FROM dim_service\", conn)\n",
        "# dim_service_df.to_csv('dim_service.csv', index=False)\n",
        "# print(\"Exported dim_service.csv\")\n",
        "\n",
        "# dim_tech_support_df = pd.read_sql(\"SELECT * FROM dim_tech_support\", conn)\n",
        "# dim_tech_support_df.to_csv('dim_tech_support.csv', index=False)\n",
        "# print(\"Exported dim_tech_support.csv\")\n",
        "\n",
        "# dim_tenure_df = pd.read_sql(\"SELECT * FROM dim_tenure\", conn)\n",
        "# dim_tenure_df.to_csv('dim_tenure.csv', index=False)\n",
        "# print(\"Exported dim_tenure.csv\")\n",
        "\n",
        "# # Export fact table data to CSV\n",
        "# fact_churn_df = pd.read_sql(\"SELECT * FROM fact_churn\", conn)\n",
        "# fact_churn_df.to_csv('fact_churn.csv', index=False)\n",
        "# print(\"Exported fact_churn.csv\")\n",
        "\n",
        "# # Close the database connection\n",
        "# conn.close()\n",
        "# print(\"Database connection closed.\")"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported stg_customer_churn_data.csv\n",
            "Exported dim_customer.csv\n",
            "Exported dim_contract.csv\n",
            "Exported dim_service.csv\n",
            "Exported dim_tech_support.csv\n",
            "Exported dim_tenure.csv\n",
            "Exported fact_churn.csv\n",
            "Database connection closed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6SOJxXQKqmHU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}